{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/banner.png\" alt=\"Museo de Arte Metropolitano de Nueva York\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Clasificación de Obras de Arte del MET\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de Negocio\n",
    "\n",
    "Desde el Museo de Arte Metropolitano de Nueva York se nos propone el proyecto de crear un modelo que les ayude a predecir si una obra puede ser destacada o no dentro de su colección.\n",
    "\n",
    "Para ello, nos dan acceso a su repositorio de [GitHub](https://github.com/metmuseum/openaccess) donde tienen subida su colección de obras de arte subidas al completo.\n",
    "\n",
    "El proceso que seguiremos para afrontar este proyecto será:\n",
    "\n",
    "1. Limpieza de datos\n",
    "\n",
    "2. Análisis exploratorio de los datos\n",
    "               \n",
    "3. Entrenamiento, optimización y evaluación del modelo\n",
    "            \n",
    "4. Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos\n",
    "\n",
    "Puedes acceder al notebook donde se limpian los datos aquí:\n",
    "\n",
    "> [Limpieza de datos](https://github.com/albamrm/Proyecto_ML/tree/main/notebooks/01_Limpieza_Datos.ipynb)\n",
    "\n",
    "Para limpiar los datos se toman varias medidas:\n",
    "- Deshacernos de las columnas que contienen: identificadores, URL e información demasiado específica, redundante o irrelevante.\n",
    "- Tratar los datos de las columnas, normalizando los textos y transformando las columnas de las fechas, y eliminar los duplicados.\n",
    "- Imputar las filas que tengan más de un 30% de sus valores nulos, y aquellos que queden, pasarlos a nombrar como \"unknown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de los datos\n",
    "\n",
    "Puedes acceder al notebook donde se hace el análisis de los datos aquí:\n",
    "\n",
    "> [EDA](https://github.com/albamrm/Proyecto_ML/tree/main/notebooks/02_EDA.ipynb)\n",
    "\n",
    "Después de este análisis se puede interpretar lo siguiente:\n",
    "- La columna \"Is Highlight\", nuestro target, está altamente desbalanceada.\n",
    "- Las columnas \"Is Timeline Work\" e \"Is Public Domain\" son binarias, lo que las hace adecuadas para ser directamente utilizadas como características.\n",
    "- Columnas como \"Title\" y \"Dimensions\" tienen una gran cantidad de valores únicos y alta cardinalidad, lo que puede hacerlas menos útiles para el modelado debido a su gran variedad y especificidad.  \n",
    "- Las columnas \"Artist\", \"Culture\", \"Period\", \"Object Name\", \"Medium\", \"Country\" y \"Credit Line\" pueden ser útiles para la categorización y pueden requerir técnicas de codificación como one-hot encoding para su uso en el modelo.  \n",
    "- Como variables numéricas tenemos las columnas \"Date\" y \"Acquisition Year\", que también pueden ser interesantes para el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento, optimización y evaluación del modelo\n",
    "\n",
    "Puedes acceder al notebook donde se hace el modelado de los datos aquí:\n",
    "\n",
    "> [Modelo](https://github.com/albamrm/Proyecto_ML/tree/main/notebooks/03_Modelo_Clasificación.ipynb)\n",
    "\n",
    "En un primer momento, nos aventuramos a entrenar con diferentes modelos haciendo caso omiso del desbalance que presenta nuestro target, y como era de imaginar, la clase minoritaria tenía una precisión casi nula, por lo que nos vemos obligados a usar técnicas como \"SMOTE\" y \"Class Weights\" para intentar paliar este problema.\n",
    "\n",
    "Para la elección del modelo hemos utilizado la validación cruzada para ver que modelo era el que mejor se adaptaba a nuestro fin, la cual nos recomendaba utilizar el modelo Extreme Gradient Boosting Classifier. Aun así, nosotros hemos entrenado y optimizado varios modelos para ver cuál daba mejor resultado de todos.\n",
    "\n",
    "Tras entrenar y optimizar todos los modelos, los evaluamos y vemos que todos los modelos tienen un buen balance entre precisión y recall para la clase mayoritaria (False), pero que aunque el recall para la clase minoritaria (True) ha mejorado significativamente, con respecto al entrenamiento sin el uso de las técnicas de rebalanceo, su precisión sigue siendo baja.\n",
    "\n",
    "En cuanto a la elección de un modelo u otro, todos tienen un rendimiento similar, por lo que la elección del modelo puede depender de otros factores como el tiempo de entrenamiento, interpretabilidad y recursos computacionales. En este caso utilizaremos XGBoost Classifier (Extreme Gradient Boosting Classifier).\n",
    "\n",
    "|          | precision | recall | f1-score | support |\n",
    "|----------|-----------|--------|----------|---------|\n",
    "| False    | 1.00      | 0.97   | 0.98     | 81052   |\n",
    "| True     | 0.11      | 0.70   | 0.19     | 448     |\n",
    "|          |           |        |          |         |\n",
    "| accuracy |           |        | 0.97     | 81500   |\n",
    "| macro avg| 0.55      | 0.83   | 0.59     | 81500   |\n",
    "| weighted avg | 0.99  | 0.97   | 0.98     | 81500   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "Para las predicciones contamos con un notebook y una aplicación de streamlit, los cuales puedes encontrar aquí:\n",
    "\n",
    "> [Notebook](https://github.com/albamrm/Proyecto_ML/tree/main/notebooks/04_Predicciones.ipynb)\n",
    "\n",
    "> [Aplicación](https://github.com/albamrm/Proyecto_ML/tree/main/app/app.py)\n",
    "\n",
    "Para predecir si una obra será destacada o no mediante la introducción de nuevos inputs, tenemos un notebook donde utilizamos el modelo anteriormente entrenado para emplearlo en el dataset al completo. A su vez, contamos con una aplicación de streamlit, donde introduciendo los diferentes datos de una obra, la aplicación te dirá si sería destacada y en qué probabilidad.\n",
    "\n",
    "Para ejecutar la aplicación de streamlit, se debe abrir el terminal, acceder a la ruta donde tengamos la aplicación y ejecutar el comando _streamlit run app.py_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Tras el trabajo realizado podemos concluir que predecir si una obra de arte será destacada o no, es una tarea difícil.\n",
    "\n",
    "Para un experto en arte es muy difícil, por no decir imposible, saber si un artista o una obra pueden despuntar. Con nuestro modelo intentamos ayudar en esta tarea, pero al topar con los datos podemos ver que se hace muy difícil crear un modelo que sea fiable al 100% en este aspecto.\n",
    "\n",
    "Por otro lado, se trata de un problema en el que los datos pueden ir cambiando y aumentando, lo que haría que el modelo tuviera que reentrenarse y así ir mejorando su capacidad de análisis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
